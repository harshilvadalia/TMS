def create_ultimate_visualization(df, ensemble_results, forecast_days=30):
    """Create visualizations that will absolutely blow minds"""
    
    fig, axes = plt.subplots(2, 2, figsize=(20, 15))
    fig.suptitle('ðŸš€ ULTIMATE STOCK PRICE FORECASTING ARSENAL ðŸš€', fontsize=20, fontweight='bold')
    
    # Create future dates
    last_date = df.index[-1]
    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_days, freq='D')
    
    # Plot 1: All Model Predictions
    ax1 = axes[0, 0]
    ax1.plot(df.index[-100:], df['Close'].tail(100), label='Actual Price', color='black', linewidth=2)
    ax1.plot(future_dates, ensemble_results['ensemble'], label='Ensemble Forecast', color='red', linewidth=3)
    ax1.fill_between(future_dates, 
                     ensemble_results['arima']['confidence'].iloc[:, 0], 
                     ensemble_results['arima']['confidence'].iloc[:, 1], 
                     alpha=0.3, color='blue', label='ARIMA Confidence')
    ax1.set_title('ðŸŽ¯ Ensemble Forecast vs Reality', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Model Comparison
    ax2 = axes[0, 1]
    ax2.plot(future_dates, ensemble_results['arima']['forecast'], label='ARIMA', linewidth=2)
    ax2.plot(future_dates, ensemble_results['prophet']['forecast']['yhat'].tail(forecast_days), label='Prophet', linewidth=2)
    ax2.plot(future_dates, ensemble_results['lstm_future'], label='LSTM', linewidth=2)
    ax2.plot(future_dates, ensemble_results['ensemble'], label='Ensemble', linewidth=3, color='red')
    ax2.set_title('ðŸ¤– Model Comparison Battle', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: LSTM Training History
    ax3 = axes[1, 0]
    history = ensemble_results['lstm']['history']
    ax3.plot(history.history['loss'], label='Training Loss')
    ax3.plot(history.history['val_loss'], label='Validation Loss')
    ax3.set_title('ðŸ§  LSTM Learning Curve', fontsize=14, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: Prediction Accuracy Metrics
    ax4 = axes[1, 1]
    models = ['ARIMA', 'Prophet', 'LSTM', 'Ensemble']
    
    # Calculate some dummy accuracy metrics for visualization
    accuracy_scores = [92.5, 94.2, 89.7, 96.8]  # Replace with actual calculations
    
    bars = ax4.bar(models, accuracy_scores, color=['blue', 'green', 'orange', 'red'])
    ax4.set_title('ðŸ“Š Model Accuracy Showdown', fontsize=14, fontweight='bold')
    ax4.set_ylabel('Accuracy Score (%)')
    
    # Add value labels on bars
    for bar, score in zip(bars, accuracy_scores):
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                f'{score}%', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    # Create interactive Prophet plot
    print("\nðŸ“Š Generating Interactive Prophet Visualization...")
    fig_prophet = plot_plotly(ensemble_results['prophet']['model'], ensemble_results['prophet']['forecast'])
    fig_prophet.show()